\documentclass[a4paper, 12pt]{report}
\usepackage[UTF8]{ctex}
\usepackage{graphicx} % for pictures
\usepackage[margin=2cm]{geometry}
\usepackage{tocloft} % for tableofcontents
\usepackage{float} % for pictures
\usepackage{xeCJK}% for chinese input
\usepackage{setspace} % for line spacing
\usepackage{anyfontsize}% set font size
\usepackage{titlesec} % set chapter style
\usepackage{CJKnumb} % for chinese number
\usepackage{titletoc} % title in TOC
\usepackage{amsmath} % for mathematical expressions, such as matrix
\usepackage{caption} % captipon setting
%\usepackage{color,soul} % highlight text


%%% font settings
\setCJKmainfont{SimSun}
\setmainfont{Times New Roman}
%\newCJKfontfamily[mingliu]\mlu{MingLiU}

\captionsetup{labelsep=space} % remove colon in caption
\captionsetup[table]{labelsep=space}

%%% format settings
% 要注意，latex的字号变动会覆盖baselineskip
% latex默认的baselineskip是fontsize的1.2倍，所以改了fontsize之后baselineskip也变了
% 行距计算：baselineskip * baselinestretch，baselinestretch和linespread其实是差不多的，只是取值不一样，后者取1.3对应前者的1.5，1.6对应2；所以一般设置行距直接改后面的因子

%%% new commands
\newcommand{\mainheader}{东南大学 2019 届本科生毕业设计（论文）}
\renewcommand{\contentsname}{\centerline{ \fontsize{16}{19.2} \selectfont \heiti 目 \qquad 录 } }
\renewcommand{\cftchapleader}{\cftdotfill{\cftdotsep}}
\renewcommand{\cftdot}{$\cdot$}
\renewcommand{\cftdotsep}{1}
\setlength{\cftbeforechapskip}{12pt}
\newcommand{\acknowledgementtitle}{致\qquad 谢}
\newcommand{\acknowledgementtitletoc}{致谢}


%%% 中文摘要
\renewenvironment{abstract}[1]
{
\newcommand{\keywords}{#1}
\phantomsection
\addcontentsline{toc}{chapter}{摘要\quad }

\vspace*{12pt}
\begin{center}
\fontsize{18}{21.6}\selectfont 摘\qquad 要
\end{center}
}
{
  \\[1\baselineskip]
  关键词： \keywords
}

%%% 英文摘要
\newenvironment{englishabstract}[1]
{
\newcommand{\keywords}{#1}
\phantomsection
\addcontentsline{toc}{chapter}{Abstract\quad }

\vspace*{12pt}
\begin{center}
Abstract
\end{center}
}
{
\\[1\baselineskip]
KEY WORDS: \keywords
}

%%% 章节格式
\titleformat
{\chapter} % command
{\centering \heiti \fontsize{15}{18} \selectfont} % format
{第\CJKnumber{\thechapter}章} % label
{0.1ex} % sep
{
   \centering
} % before-code

%%% 目录中章节
\newcommand{\titlecontentschapter}{%
\titlecontents{chapter}[0pt]{\vspace{.5\baselineskip}\normalfont}
{第\CJKnumber{\thecontentslabel}章\quad}{}
{\hspace{.5em}\titlerule*[4pt]{$\cdot$}\contentspage}
}

%%% 致谢
\newenvironment{Acknowledgement}[1][\acknowledgementtitle]
{%
  
  \phantomsection
  \addcontentsline{toc}{chapter}{\acknowledgementtitletoc}
  \chapter*{#1}

}{\par}











\begin{document}

%%% 封面
\vspace*{36pt}
\thispagestyle{empty}
\begin{figure}[H]
\centering
\includegraphics[width=4.28in, height = 1.52in]{seu}
\end{figure}
\vspace{16pt}

\begin{center}
{\fontsize{16}{46}\selectfont % first : fontsize; second : baselineskip

\textbf{题目} \quad \underline{\makebox[250pt][c]{\textbf{图像去雾化方法研究}}}\\
\underline{\makebox[100pt][c]{\textbf{交通学院}}}院（系）\quad \underline{\makebox[100pt][c]{\bf 交通工程}}专业 \\
学\qquad 号 \underline{\makebox[300pt][c]{\textbf{21015111}}}\\
学生姓名 \underline{\makebox[300pt][c]{\textbf{周冬秦}}}\\
指导教师 \underline{\makebox[300pt][c]{\textbf{何铁军\  教授}}}\\
起止日期 \underline{\makebox[300pt][c]{\textbf{2019年2月25日至2019年6月2日}}}\\
设计地点 \underline{\makebox[300pt][c]{\textbf{东南大学交通学院203室}}}\\
}
\end{center}
\newpage

%%% 独创性声明、授权声明
\thispagestyle{empty}
\vspace*{36pt}
\begin{center}
\textbf{\fontsize{16}{19.2} \selectfont 东南大学毕业（设计）论文 \\ \medskip 独创性声明}
\end{center}
\par 本人声明所呈交的毕业（设计）论文是我个人在导师指导下进行的研究工作及取得的研究成果。尽我所知，除了文中特别加以标注和致谢的地方外，论文中不包含其他人已经发表或撰写过的研究成果，也不包含为获得东南大学或其它教育机构的学位或证书而使用过的材料。与我一同工作的同志对本研究所做的任何贡献均已在论文中作了明确的说明并表示了谢意。
\begin{flushright}
论文作者签名：\rule{2cm}{0.05em} \quad 日期：\rule{2cm}{0.05em}
\end{flushright}
\vspace{4cm}

\begin{center}
\textbf{\fontsize{16}{19.2} \selectfont 东南大学毕业（设计）论文使用 \\ \medskip 授权声明}
\end{center}
\par 东南大学有权保留本人所送交毕业（设计）论文的复印件和电子文档，可以采用影印、缩印或其他复制手段保存论文。本人电子文档的内容和纸质论文的内容相一致。除在保密期内的保密论文和在技术保护期限内的论文外，允许论文被查阅和借阅，可以公布（包括以电子信息形式刊登）论文的全部或中、英文摘要等部分内容。论文的公布（包括以电子信息形式刊登）授权东南大学教务处办理。
\begin{flushright}
论文作者签名：\rule{2cm}{0.05em} \quad 导师签名：\rule{2cm}{0.05em} \quad 日期：\rule{2cm}{0.05em}
\end{flushright}
\newpage

%%% 摘要
\pagenumbering{Roman}
\begin{abstract}{半固态，ZA12合金，触变性能，流变性能，表观黏度，流变模型}
{\setstretch{1.5}
\par 本文用自行研制的高温同轴双筒流变仪，研究了半固态ZA12合金的流变性能。
对半固态ZA12合金的剪切应力与时间关系曲线和滞回环进行了测试和分析。结果表明半固态ZA12合金具有触变性，其触变性的大小与固相分数和剪切速率有关。在稳态和瞬态的不同条件下，半固态ZA12浆液表现出不同的流体特征。在稳态条件下，半固态ZA12合金的表观黏度随剪切速率的增加而下降，呈现出假塑性的流变特性；而在瞬态条件下，其表观黏度随剪切速率的增加而增大，呈现出胀流性的流变特性。
\par 最后，根据瞬态条件下的试验结果以及流变学理论，建立了能适应实际工况条件的ZA12合金的动态流变模型。
}
\end{abstract}

\newpage

\begin{englishabstract}{semi-solid, ZA12 alloy, thixotropic behavior, rheological behavior, apparent viscosity, rheological model}
\par In this thesis, the rheological behavior of semi-solid ZA12 alloy was investigated using a specially designed high temperature Couette rheometer.
\par The evolution of shear stress with time and the hysteresis loops of semi-solid ZA12 alloy were measured and analyzed. The results show that semi-solid ZA12 alloy possesses the thixotropic property, which varies with solid fraction and shear rate. In addition, the semi-solid ZA12 alloy slurry exhibits different rheological behaviors under steady state and transient state conditions. In case of steady state, the apparent viscosity of semi-solid ZA12 alloy decreases with the increase of shear rate, showing the pseudo-plastic rheological behavior. However, under the transient state condition, it presents the dilatant rheological behavior, i.e. the apparent viscosity increases as shear rate increases.
\par Finally, based on the transient state experimental results and rheology theory, a dynamic rheological model of semi-solid ZA12 alloy was developed, which could be applicable to practical semi-solid processes.
\end{englishabstract}
\newpage

%%% 目录
\vspace*{12pt}
{\fontsize{12pt}{18pt} \selectfont
\tableofcontents
}\thispagestyle{empty}
\newpage

%%% 正文
\pagenumbering{arabic}
\titlecontentschapter   % 在这里才启用前面定义的目录章节格式，不在前面启用，因为摘要也算作章节，牛逼！
\chapter{绪论\quad}
\section{研究背景和意义\quad}
信息化时代的一大特征即是海量数据的存储，例如图片、视频、音频、文本数据等。以图片数据为例，绝大部分的图片都采集于室外，但室外采集的图片相比于室内图片，更容易受到空中浑浊物，如水滴、悬浮颗粒的降质影响。降质图片无法反映原景物的对比度和真实颜色，降低观赏性，某些图片还会丢失重要信息，如交叉口抓拍图片。

图像去雾化处理是一个热门的研究领域。一方面，图像去雾能够有助于高层次的计算机视觉研究，如目标检测、无人驾驶等；另一方面，经过去雾处理的图片能够较好地纠正色差，更具观赏性。此外，在去雾处理中生成的深度图也会有助于图像编辑和其他视觉算法[1]。

含雾图片形成可以由大气散射模型来描述，这一模型最初是由McCartney[2]提出来的，之后由Narasimhan和Nayar[3, 4]进一步发展。模型表达式如下：
\begin{equation}
{\bf I(x)} = {\bf J(x)}t{\bf (x)} + {\bf A}(1 - t{\bf (x)})
\end{equation}
其中，I是获取的含雾图片，J是对应的无雾图片，t是介质散射率，A是大气光值。去雾的目的即为，根据已有的I，获取对应的J，A，t。若介质时均质的，介质散射率可以表示为：
\begin{equation}
t{\bf (x)} = e^{-\beta d{\bf (x)}}
\end{equation}
其中，β是大气散射系数，为未知值，d为景深。

\section{研究现状\quad}
由大气散射模型可知，图像去雾的关键步骤在于估计出透射图和大气光。含雾图片的形成及其逆过程图像去雾都与景深有关。对于一张随意采集的图像，我们无法获取其景深，因此单幅图片的去雾是一个约束不足的问题。

针对这一困境，许多学者提出使用多幅图像获取附加信息进行去雾[3, 5, 6, 7, 8]，但这些方法的应用场景会受到限制。以自动驾驶为例，行驶中的车辆无法对同一处景物进行多次拍照，而多个摄像头同时拍照则无法保证拍照取景完全一致，难以获取同一景物的多幅图像；此外，此类算法需要对多幅图片进行处理，速率较慢，而自动驾驶车辆获取的数据量巨大，如特斯拉自动驾驶汽车8个摄像头每秒有2100帧输入图像，多幅图像去雾无法满足其处理速度要求。

理想的去雾算法可以对摄像头拍摄的图片进行实时去雾，因此单幅图片的高效、快速去雾成为研究的热点。目前，单幅图像去雾主要有两类较高效的方法：基于先验知识的去雾方法和基于神经网络的去雾方法，这两类方法都基于上述的大气散射模型。除此之外，还有不基于物理模型的图像增强方法，如直方图均衡化算法[9]、Retinex算法[10]等，但此类方法不考虑有雾图像的生成原因，直接对关注的细节进行增强，虽然简便易行，但容易丢失图像信息，使图像失真，本论文不对此类算法进行深入研究。

\subsection{基于先验知识的去雾算法\quad}
Tan [11] 等人观察到无雾图像比其对应有雾图像的对比度高，于是采用了最大化对比度的方法来去除图像中的雾，该方法在视觉上能取得一定的效果，但是容易使图像过饱和及颜色失真。Fattal [12] 假设透射率局部不相关、反射率局部为常数，估计出景物的反射率并推导出透射率，进而计算出原图像，这一方法假设太强并且未考虑到景物深度的结构，导致无法处理浓雾图像并且不能准确估计景物深度。He [1] 等人在统计分析大量无雾图像后，于2009年提出了基于暗通道先验的去雾算法。这一方法非常简单，其去雾效果却非常好。He最初提出该方法时采用了软抠图的方法来优化透射率，但是该方法计算效率太低，其在2013年提出的引导滤波 [13] 方法可以大幅度提升计算效率。在He之后，有许多学者研究如何改进He的算法以使其适用于天空区域，并尝试优化透射率的估计以及计算效率。这一方法主要问题是对于含天空区域的图像，暗通道会失效，天空区域进行去雾处理后会失真。Zhu [14] 等人提出了基于颜色衰减先验的去雾方法，该方法提出了一个线性模型来表示颜色衰减先验下含雾图像中的景物深度，之后采用监督学习的方法学习到模型参数，从而获取图像中的深度信息，并以此来估计透射图从而给图像去雾。Berman [15]提出了基于非局部先验的去雾方法，该方法假设无雾图像中每个颜色团簇都是RGB空间中的一条雾线。

\subsection{基于神经网络的去雾算法\quad}
随着卷积神经网络的兴起及其在计算机视觉领域的大规模应用，一些去雾算法也开始应用卷积神经网络。Cai [16] 等人提出了一个可训练的系统DehazeNet，用以估计含雾块的透射率，而后将此系统应用到整张图片以获取含雾图片的透射图，从而根据大气散射模型计算出无雾图片。Ren [17] 等人提出了一个多尺度卷积神经网络 (MSCNN) 用以直接估计与含雾图片对应的透射图，该方法先使用粗尺度模型对含雾图像进行处理，之后将此模型输出和原含雾图像作为细尺度模型的输入，而后使用细尺度模型输出的透射图进行无雾图像的计算。Li [18] 等人提出了一个端到端的去雾网络AOD-Net，该方法先将透射率t和大气光A重建为一个新的变量，而后使用两个模块构成的AOD-Net对含雾图像进行端到端的处理。

\section{研究目的和研究内容\quad}
本论文旨在探索图像去雾化的研究前沿，实现去雾算法，并对其效果进行对比。此外，本论文将去雾算法应用到雾天视频，以提供更好的路面交通信息。

本论文主要内容是实现去雾领域较为代表性的算法，例如暗通道法（DCP），DehazeNet, MSCNN, AOD-Net。第一章介绍去雾研究的背景意义，去雾研究的现状综述。第二章以暗通道法为例介绍基于先验知识的图像去雾算法，第三章以DehazeNet, MSCNN, AOD-Net为主要内容介绍基于神经网络的去雾算法。第四章介绍领域内广泛使用的数据集，以及上述各算法具体实现和其性能评估。第五章总结全文并提出后续研究方向和本研究应用前景展望。


\chapter{基于先验知识的去雾算法研究\quad}
本章以暗通道法为例介绍基于先验知识的去雾算法，并对该算法进行描述性的评价。先验知识为不对问题进行具体处理即可知道的知识，即先于经验之前的知识。与之对应的是后验知识，即在有经验之后的知识。去雾处理中的先验知识，即不对图像进行去雾，只凭观察对比含雾图像或去雾图像就能获得的知识。在应用神经网络的去雾方法变得较为流行之前，单幅图像的去雾方法主要是基于不同的先验知识，如本章介绍的暗通道先验。
\section{暗通道\quad }
暗通道是He[1]等人观察分析大量无雾图片所得出的。他们发现，大多数户外无天空区域的图片块中存在某些像素点，这些像素点有至少一个很小的RGB分量值，也就是说这些图片块中最小的像素值很小，甚至接近于0。这一发现可由下式表示：
\begin{equation}
{\bf J}^{dark}{\bf (x)} = \min_{c \in \{r, g, b\}}(\min_{{\bf y} \in \Omega({\bf x})}(\bf J^c(y)))
\end{equation}
其中，J是一张图片，$J^c$是其中一个颜色通道，$\Omega(x)$是以x为中心的一个图片块。他们观察到$J^{dark}$非常小，且接近于0，于是将$J^{dark}$称为图片J的暗通道，而将上式(3)称为暗通道先验。

	暗通道的发现也有其物理背景。He等人提出，户外图片常常具有很多阴影，并且是具有多种颜色的，而阴影的存在会使得各通道像素值较小，具有鲜明颜色的物体则往往会缺少某一通道的颜色，使得该通道像素值较小，因此户外无天空区域图像的暗通道确实应该是暗的。理论分析之外，他们从网上搜集了5000张无雾风景图，裁剪掉天空区域并统计了他们的暗通道像素强度，统计数据也支持了他们提出的暗通道理论。



\section{透射图估计\quad }
估计透射图之前，He等人先假设大气光值A已给定且为常数，并且假设以x为中心的局部区域内透射率为常数，记之为$\tilde{t}(x)$，对大气散射模型(1.1)两端取最小值则有
\begin{equation}
\min_{{\bf y} \in \Omega({\bf x})}({\bf I}^c({\bf y})) = \tilde{t}(x) \min_{{\bf y} \in \Omega({\bf x})}({\bf J}^c({\bf y})) + (1-\tilde{t}(x)){\bf A}^c
\end{equation}
两端同时除以大气光值有
\begin{equation}
\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf I}^c({\bf y})}{{\bf A}^c}) = \tilde{t}(x)\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf J}^c({\bf y})}{{\bf A}^c}) + (1-\tilde{t}(x))
\end{equation}
在三个通道之内取最小值有
\begin{equation}
\min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf I}^c({\bf y})}{{\bf A}^c})) = \tilde{t}(x)\min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf J}^c({\bf y})}{{\bf A}^c})) + (1-\tilde{t}(x))
\end{equation}
根据暗通道先验有
\begin{equation}
{\bf J}^{dark}{\bf (x)} = \min_c(\min_{{\bf y} \in \Omega({\bf x})}(\bf J^c(y))) = 0
\end{equation}
而大气光值$A^c$恒为正值，则有
\begin{equation}
\min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf J}^c({\bf y})}{{\bf A}^c})) = 0
\end{equation}
联式(2.4)和(2.6)有
\begin{equation}
\tilde{t}(x) = 1 - \min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf I}^c({\bf y})}{{\bf A}^c}))
\end{equation}

在含雾图片中，天空区域的颜色和大气光值很相近，因此由(2.7)计算出天空区域透射率为
$$\min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf I}^c({\bf y})}{{\bf A}^c})) \rightarrow 1,\ \tilde{t}(x) \rightarrow 0$$
而天空是在无限远处的，透射率应当为0，这一结果与(2.7)式计算结果一致，因此计算透射率时无需区分开天空区域和非天空区域。

在实际中，即便是无雾天气空中也会存在小颗粒，在远眺时图像仍会被降质。而倘使将小颗粒全部去除，即令$\tilde{t}(x) = 0$，则人眼无法感知景物深度，使看到的景物不真实，因此可在(2.7)中引入一个常数$\omega$以保留空中的部分颗粒，结果如下
\begin{equation}
\tilde{t}(x) = 1 - \omega\min_c(\min_{{\bf y} \in \Omega({\bf x})}(\frac{{\bf I}^c({\bf y})}{{\bf A}^c}))
\end{equation}
其中，$\omega$取值为0.95。

\section{引导滤波\quad}
He等人初始提出暗通道法时，采用的是软抠图方法对(2.8)计算出的透射图进行优化，但该方法计算效率太低，难以应对快速的去雾处理。其在2013年提出的引导滤波[13]方法能够较好地提升计算效率，同时保持了暗通道法较好的去雾效果。

\subsection{滤波\quad}
一张图片可以视作一个函数，自变量为图片中像素点的位置，因变量为像素值的大小，由此我们可以得到与每张图片唯一对应的一个函数。如是灰度图片，自变量为二元坐标值(x, y)，因变量$f(x, y)$则为处于0-255之间的一个整数值；如是彩色图片，自变量仍为二元坐标值(x, y)，因变量则为$3\times 1$的向量，该向量分量值为每个颜色通道的像素值（0-255之间的整数）
$$ f(x. y) = 
\begin{vmatrix}
  r(x, y) \\
  g(x, y) \\
  b(x, y)  
\end{vmatrix}
$$

滤波的作用即改变像素点位置对应的像素值，即$f(x,y)$，但不改变像素点的位置(x,y)，是常用的图像增强、提取图像信息的手段。常用滤波器有线性时不变滤波器，如均值滤波、中值滤波、高斯滤波，这类滤波器有显式声明的核函数，不因图片内容产生变化。例如，均值滤波会用每个像素点周围窗口内像素值的平均值取代该像素点原值：
$$g(x) = \frac{1}{|\Omega(x)|}\sum_{y \in \Omega(x)}f(y)$$
式中$\Omega(x)$为以x为中心的窗口大小，该大小可自定义，$|\Omega(x)|$为该窗口内像素点的个数。图2.1是含有高斯噪声的图片，我们使用均值滤波对该图片去噪，窗口大小选择为$7\times 7$，去噪效果如图2.2所示。
\begin{figure}[htbp]
\centering
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=8cm]{noisy}
\caption{含噪图片}
\end{minipage}
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=8cm]{de-noisy}
\caption{去噪图片}
\end{minipage}
\end{figure}
均值滤波算法简单，对图像处理速度较快，但在降低噪声的同时容易使图像变模糊，尤其是图像边缘部分。此外，均值滤波较适合高斯噪声的去噪，对椒盐噪声处理效果较差。除线性时不变滤波器之外，有时候我们想利用图片的信息进行对图片进行滤波处理，因而需要使用一张引导图像，即引导滤波。

\subsection{引导滤波\quad}
引导滤波的输入为引导图像I，被引导图像p，滤波器半径大小r，正则化参数$\epsilon$，输出为滤波处理后的图像q。引导滤波的关键假设是引导图像I与滤波输出q之间存在线性关系，在以像素点k为中心的窗口$\omega_k$中，滤波输出是引导图像的线性转换
\begin{equation}
q_i = a_k I_i + b_k, \forall i \in \omega_k
\end{equation}
其中，$(a_k, b_k)$是在窗口$\omega_k$中为常数的线性系数。此滤波器使用以r为半径大小的窗口。

我们通过最小化滤波器输入p与输出q之间的差异来确定线性系数的大小，由此定义的损失函数为
\begin{equation}
E(a_k, b_k) = \sum_{i\in \omega_k}((a_k I_i + b_k - p_i) + \epsilon a_k^2)
\end{equation}
其中$\epsilon$是正则化系数，用以惩罚过大的系数$a_k$。最小化上述损失函数，得
\begin{equation}
a_k = \frac{\frac{1}{|\omega|}\sum_{i\in \omega_k}I_ip_i - \mu_k\bar{p_k}}{\sigma_k^2 + \epsilon}
\end{equation}

\begin{equation}
b_k = \bar{p_k} - a_k \mu_k
\end{equation}
其中，$\mu_k$和$\sigma_k^2$是引导图像在窗口$\omega_k$中的均值和方差，$|\omega|$是窗口内像素点的个数，而$\bar{p_k} = \frac{1}{|\omega|}\sum_{i\in \omega_k}p_i$是窗口内被引导图像的均值。得到线性系数$(a_k, b_k)$值后，我们即可通过(2.9)式计算滤波器输出。

值得注意的是，图片中某个像素点i不为某一个窗口专属，因此在不同窗口下根据(2.9)式计算出的$q_i$并不一样。对此，一个较为简单可行的方法是对$q_i$所有可能值取平均。因此，在计算出每个窗口中的线性系数之后，我们可以通过下式计算滤波器输出
\begin{equation}
q_i = \frac{1}{|\omega|}\sum_{k|i\in \omega_k}(a_k I_i + b_k)
\end{equation}
也即
\begin{equation}
q_i = \bar{a_i}I_i + \bar{b_i}
\end{equation}
其中，$\bar{a_i} = \frac{1}{|\omega|}\sum_{k\in \omega_i}a_k$和$\bar{b_i} = \frac{1}{|\omega|}\sum_{k\in \omega_i}b_k$是包含像素点i的所有窗口中线性系数的均值。式(2.11), (2.12), (2.14)即是引导滤波的定义。由以上介绍的算法，我们可以对2.2节中估计出的透射图进行优化，以此得到更精确的透射图。

\section{大气光估计\quad}
He等人提出的{\Large 暗通道可用以估计图片中雾的厚度}：暗通道中亮度值越高，表明原图中该区域雾越厚。由此，He等人提出，先选取暗通道中前0.1\%亮度值最高的像素点，在这些像素点中选取原图中的最高亮度值作为大气光A。

\section{无雾图像计算\quad}
如前所述，根据大气散射模型(1.1)进行图像去雾处理，最关键步骤是计算出透射图和大气光。值得注意的是，在介质透射率较小甚至趋近于0时，根据模型获取的无雾图像易产生较大噪声，因此需要对透射率最小值进行限制，可由下式进行无雾图像的计算
\begin{equation}
{\bf J(x)} = \frac{\bf I(x) - A}{max(t({\bf x}), t_0)} + {\bf A}
\end{equation}
其中，$t_0$取值0.1。

\section{算法评价\quad}
He等人提出的暗通道法毫无疑问是单幅图像去雾的标志性工作。该方法原理非常简单，但是去雾效果非常好。在暗通道法提出后，许多学者对此方法表现出极大兴趣，并致力于改进该算法，以使其更好的适用于天空区域。

与此同时，我们也应当意识到这一方法的局限性，其一，是多次提到过的，该方法不适用于存在和天空颜色较为相似的物体的图片，因为在此类图片中，暗通道会失效。其二，是所有基于大气散射模型的去雾算法共有的局限性——该大气散射模型也许无法准确描述含雾图片的生成。

\chapter{基于神经网络的去雾算法研究\quad}
本章着重介绍几种广为人知的基于神经网络的去雾算法，DehazeNet, MSCNN, AOD-Net。神经网络以其强大的非线性拟合能力在学界掀起了一股热潮，而卷积神经网络以其对图像的卓越处理能力成为了计算机视觉领域的标志性算法。本章将先介绍卷积神经网络的基本结构，如卷积层、池化层等，再深入讲解以卷积神经网络为基础的去雾算法。

\section{卷积神经网络\quad}
卷积神经网络最早是由Yang LeCun提出的，但当时并未引起较大注意。之后的十几年，计算能力显著提高，CPU越来越快，GPU成为常用的计算工具，智能手机、摄像头的广泛应用使人们可以获取海量数据，大量的数据和不断提高的计算能力让神经网络的训练变得越来越易行。2012年由Alex Krizhevsky提出的AlexNet在ImageNet图像识别比赛中大幅获胜，激起了卷积神经网络的热潮，并由此拉开了深度学习的时代序幕。自那时起，卷积神经网络便成为了深度学习的一把利器。

典型的卷积神经网络一般含有卷积层、池化层和全连接层。

\subsection{卷积层\quad}
卷积操作和上述线性时不变滤波器对图片进行的操作是类似的，如图3.1所示，其中I为需进行卷积操作的图层，K为卷积核，卷积结果为I * K（也常记为$I\otimes K$）。卷积层一般用于提取前一层的局部特征，卷积核即特征提取器。
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{convolution}
\caption{卷积操作}
\end{figure}
以彩色图片为输入层时，其大小为M * N * D，其中M为图片高度，N为图片宽度，D为图片深度，即颜色通道个数，彩色图片通道个数为3（D = 3）。不失一般性，不妨假设输入卷积层的张量大小为M * N * D，记为X，进行卷积操作后输出层张量大小为 $M^{\prime} * N^{\prime} * P$，记为Y，则卷积核张量大小为m * n * D * P，记为W，其中，m，n为二维卷积核大小，P为输出特征图的个数。

卷积层计算输出特征图$Y_p$时，用卷积核$W_p$（大小为m * n * D）对输入张量X进行卷积操作，加上偏置标量$b_p$即得到卷积层的净输入$Z_p$，$Z_p$经过激活函数得到特征图$Y_p$。其计算过程如下
\begin{equation}
Z^p = W^p \otimes X + b^p = \sum_{d = 1}^D W^{p, d} \otimes X^d + b^p
\end{equation}

\begin{equation}
Y^p = f(Z^p)
\end{equation}
其中，f为激活函数，常用的激活函数有tanh, ReLU, sigmoid, Leaky ReLU。一个卷积层需要P * D * （m * n） + P个参数。

\subsection{池化层\quad}
池化层，又叫下采样层，一般置于卷积层之后，目的是进行特征选择，减少特征数量。常用的池化函数有最大池化和平均池化，两者作用原理如图3.2所示。
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{pool}
\caption{池化操作}
\end{figure}
池化层的一般操作是将每张特征图划分为2*2的不重叠区域，对每个区域使用最大池化或平均池化函数。其中，划分区域及池化函数可以自定义，但过大的划分区域会导致信息的过分损失。

\subsection{上采样层\quad}
上采样层与池化层对应，类似于池化层的逆操作，即将一个像素点的值扩充至以该像素点为中心的窗口，窗口大小可以自己定义，一般选择$2\times 2$的窗口。其过程如图3.3所示，此图选择的窗口大小为 $3 \times 3$。
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{upsample}
\caption{上采样操作}
\end{figure}

\section{DehazeNet\quad}
由大气散射模型可知，图片去雾最关键步骤在于透射图的估计，由是Cai[16]等人提出了一个端到端预测透射率的系统，该网络架构如图3.4所示。值得注意的是，该网络输入层是大小为16 * 16 * 3的图片块，输出结果是该图片块的透射率，这一性质将在第四章详细讨论。
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{DehazeNet}
\caption{DehazeNet网络结构}
\end{figure}

\subsection{特征提取层\quad}
特征提取层通过卷积操作和非线性激活函数实现。卷积操作使用16个大小为5 * 5 * 3的卷积核，不同于一般使用ReLU或tanh激活函数，这一层使用Maxout [19] 激活函数，并设置其参数为k=4。以下使用一个简单的例子讲解Maxout激活函数。
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{Maxout}
\caption{传统激活函数与Maxout激活函数}
\end{figure}
上图中，(a)表示传统的激活函数，(b)表示Maxout激活函数。(a)中，我们有$$Y = f(W \otimes X + b)$$
其中，f为常用的激活函数，如tanh，ReLU，sigmoid，参数个数为 2 + 1 = 3个。(b)中，我们有
\begin{equation}
Y = \max\{W_1 \otimes X + b_1, W_2 \otimes X + b_2, W_3 \otimes X + b_3, W_4 \otimes X + b_4, W_5 \otimes X + b_5\}
\end{equation}
其中参数个数有 (2 + 1) * 4 = 12个。由此知，Maxout单元会成倍的增加参数个数，成倍因子为Maxout单元的参数k。

由式(3.3)可知，Maxout激活单元是分段的线性函数，因而可以拟合任意的凸函数，如图3.6所示。
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{Maxout-fitting}
\caption{Maxout激活单元}
\end{figure}

\subsection{多尺度映射\quad}
多尺度特征在图像去雾上被证明是较为有效的，于是本网络也采用了多尺度卷积。具体而言，三个尺度的卷积核大小分别为$3\times 3$， $5\times 5$， $7\times 7$，每个尺度均选用16个卷积核。由于上一层输出特征组中有四张特征图，因此每个卷积核的深度均为4。

\subsection{局部极值\quad}
局部极值采用最大池化，窗口大小为$7\times 7$。上一层输出特征组有16 * 3 = 48张特征图，大小均为12 * 12。因此本层局部极值的输出大小为48 * 6 * 6。

\subsection{非线性回归\quad}
本层在卷积操作之后采用双边线性整流函数(BReLU)作为激活函数。一方面，sigmoid激活函数容易导致梯度消失，进而导致较慢的收敛速度和不理想的局部极值；另一方面，ReLU激活函数比较适用于分类问题，不是非常适合回归问题，如这里的图像复原。受sigmoid函数和ReLU函数启发，DehazeNet提出使用BReLU激活函数，该函数可以保持双边约束以及局部线性。下图为BReLU和ReLU激活函数图像对比，在本方法中，$t_{min}$和$t_{max}$分别取值为0和1。

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{BReLU}
\caption{ReLU和BReLU激活单元对比}
\end{figure}
本层仅使用一个卷积核，其大小为6 * 6，因而输出张量大小为1 * 1，经过BReLU激活函数之后输出一个0-1之间的标量值，即为该图片块的透射率值。

\subsection{网络参数\quad}
下表显示了DehazeNet中各层的参数设置。在本网络中，卷积层的偏置恒为0，只设置权重参数，该网络中可训练参数共有16 * 4 * 5 * 5 + 16 * 4 * （3 * 3 + 5 * 5 + 7 * 7） + 48 * 6 * 6 = 8240个。



\begin{Acknowledgement}{}
啦啦啦
\end{Acknowledgement}



\newpage

\vspace{5cm}

\textbf{fuck}

\bigskip
你好啊啊

{\heiti 你好啊啊，黑体}

{\kaishu 你好啊啊，楷书}

%{\mlu 你好啊啊，细明体}

what the hell is going on 

{\fontsize{50}{60}\selectfont Foo}


给公式、图片、目录加超链接？


























\end{document}